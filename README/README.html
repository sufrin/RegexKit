<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bernard Sufrin" />
  <title>RegexKit</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">RegexKit</h1>
<p class="author">Bernard Sufrin</p>
<p class="date">Oxford, May and December 2022</p>
</header>
<h2 id="introduction">Introduction</h2>
<p><code>RegexKit</code> provides an implementation of (more or less) standard regular expression matching and group capture, <strong>forwards or backwards</strong>, over (subsequences of) sequences of arbitrary type. We designed it because the standared Java/Scala API was too restrictive for our application – a text editor.</p>
<p><strong>There is no backtracking for anchored matches</strong> which – in the case of a failure – take time bounded in proportion to the product of the ‘length’ of the regular expression (or, to be more precise, the number of non-housekeeping instructions in the code that it is translated to by the implementation) and the length of the subject subsequence.</p>
<p>Its <code>CharSequence</code> matching facilities are well-developed and tested (genericity came as an unplanned bonus).</p>
<p>The principal methods of the <code>CharSequence</code>-applicable API are the matching and searching methods of <code>Regex</code> that act on specified subsequences of the given subject:</p>
<pre><code>  // anchored methods
  def suffixes  (subject: CharSequence, from: Int, to: Int,   bound: Int):Option[StringMatch] 
  def matches   (subject: CharSequence, from: Int, to: Int,   bound: Int):Option[StringMatch] 

  // searching methods
  def findPrefix(subject: CharSequence, from: Int, to: Int,   bound: Int):Option[StringMatch] 
  def findSuffix(subject: CharSequence, from: Int, to: Int,   bound: Int):Option[StringMatch] 
</code></pre>
<pre><code>  // repeated searches
  def allPrefixes(subject: CharSequence, _from: Int, _to: Int, bound: Int): Iterator[StringMatch] 
  def allSuffixes(subject: CharSequence, _from: Int, _to: Int, bound: Int): Iterator[StringMatch]
</code></pre>
<p>and its substitution method, that substitutes an expanded instance of the template for each matching instance of this regular expression in the input. Return the substituted result with a count of the number of substitutions that were made. When <code>literal</code> is true, the template is not expanded.</p>
<pre><code>  def substituteAll(subject: CharSequence, template: String, literal: Boolean, bound: Int): (Int, String)</code></pre>
<p>An individual <code>StringMatch</code> has a substitute method that replaces all occurences of <code>$$</code> in the template with <code>$</code>, and all occurences of <code>$</code><em>i</em> (when <em>i</em> is a digit) with <code>group(</code><em>i</em><code>).getOrElse("")</code>.</p>
<pre><code>   def substitute(template: String): String</code></pre>
<p>The API also provides methods for scanning forwards and backwards for (properly-nested) bracketed text, whose opening and closing brackets are specified by regular expressions.</p>
<h2 id="examples">Examples</h2>
<p>The following examples are abstracted, somewhat edited, from the source code of the <code>Red</code> text editor.</p>
<p>Patterns matching the left and right boundaries of various granularities of text lump.</p>
<pre><code>   object Boundaries {
    import sufrin.regex.Regex
    val leftWord  : Regex   = Regex(&quot;&quot;&quot;\W\w&quot;&quot;&quot;)
    val rightWord : Regex   = Regex(&quot;&quot;&quot;\w\W&quot;&quot;&quot;)
    val leftLine  : Regex   = Regex(&quot;&quot;&quot;(\n|^)[^\n]*&quot;&quot;&quot;)
    val rightLine : Regex   = Regex.literal(&quot;\n&quot;) 
    val leftPara  : Regex   = Regex(&quot;(\n|^)\\s*\n&quot;)
    val rightPara : Regex   = Regex(&quot;\n\\s*(\n|$)&quot;)
   }
</code></pre>
<p>The method <code>selectChunk</code> performs a search, around the <code>start</code>, for a “chunk” (for example a word, line, or paragraph) whose left and right boundaries are specified by the regular expressions <code>l</code> and <code>r</code>. It returns the left and right boundaries of the chunk.</p>
<pre><code>
def selectChunk(start: Int, l: Regex, r: Regex, adjl: Int, adjr: Int): Option[(Int, Int)] =
    // find the last suffix matching l that ends no later than start
    l.findSuffix(document.characters, 0, start) match {
      // no such suffix
      case None =&gt; None
      // suffix extends from lp.start to lp.end
      // find the next prefix that starts no earlier than lp.end
      case Some(lp) =&gt;
        r.findPrefix(document.characters, lp.end, document.characters.length) match {
          // no such suffix
          case None =&gt; None
          // suffix extends from rp.start to rp.end
          // chunk extends from lp.start to rp.end
          case Some(rp) =&gt;
            val (start, end) =
                (if (lp.start == 0) lp.start else lp.start + adjl, rp.end - adjr)
            Some((start, end))
        }
    }</code></pre>
<p>The method <code>find</code> performs an unanchored search from the current cursor position in the indicated direction.</p>
<pre><code>  def find(pattern: String, backwards: Boolean, literal: Boolean): Boolean = {
      val chars = document.characters
      try {
        val regex = if (lit) Regex.literal(pattern) else Regex(pattern)
        if (backwards) {
          val lastMatch = regex.findSuffix(chars, 0, cursor, Utils.stepLimit)
          lastMatch match {
            case None           =&gt; feedback.notify(&quot;Not found upwards&quot;, s&quot;$pattern&quot;)
                                   false
            case Some(instance) =&gt; cursor = instance.start
                                   setMark(instance.end)
                                   true
          }
        } else {
          val nextMatch = regex.findPrefix(chars, cursor, chars.length, Utils.stepLimit)
          nextMatch match {
            case None           =&gt; feedback.notify(&quot;Not found&quot;, s&quot;$pattern&quot;)
                                   false
            case Some(instance) =&gt; cursor = instance.end min (chars.length-1)
                                   setMark(instance.start)
                                   true
          }
        }
      } catch { case exn: sufrin.regex.syntax.lexer.SyntaxError =&gt;
                notify(&quot;Find&quot;, s&quot;Pattern: &quot;$pattern&quot; is ill-formed\n${exn.getMessage}&quot;)
                false }
    }
  </code></pre>
<p>The search is for <code>pattern</code> interpreted either as a literal or as a regular expression. The cursor is moved to the start of the match, and the <em>mark</em> (the other end of the selection) is moved to the opposite end.</p>
<h2 id="branched-regular-expressions">Branched Regular Expressions</h2>
<p>A <em>branched</em> <code>Regex</code> is a <code>Regex</code> consisting of 1 or more branches, each of which is effectively an independent <code>Regex</code>. A <em>1-branched</em> <code>Regex</code> is effectively equivalent to an ordinary <code>Regex</code>, and all methods of a <code>Regex</code> can be used from a branched Regex.</p>
<p>A branched <code>Regex</code> matches, in effect, as an alternation of its components. But the <code>Match</code> or <code>StringMatch</code> objects that it yields make available an <span class="math inline"><em>i</em><em>n</em><em>d</em><em>e</em><em>x</em></span>, that indicates which of the component expressions actually matched; and the grouping numbers of <em>each</em> component are indexed from 0: unlike those of an “ordinary” alternation. Branched expresisons make it convenient to:</p>
<ul>
<li>Perform multiple simultaneous substitutions</li>
<li>Perform lexical-scans</li>
</ul>
<p>The following convenience functions may be used to generate branched regular expressions:</p>
<pre><code>Regex.fromSources(sources: Seq[String], ... ):  Regex 
Regex.fromRegexes(regexes: Seq[Regex],  ...):   Regex </code></pre>
<h3 id="simultaneous-substitution">Simultaneous Substitution</h3>
<p>The following method, a sort of simultaneous <code>substituteAll</code> in <code>input</code>, is designed specifically for use from branched regular expressions. The template used in each individual rewrite is the template corresponding to (the index of) the matching instance. There must be at least as many templates as there are branches of <code>re</code>. The groups of each instance are numbered from 1.</p>
<pre><code>  re.rewriteAll(input: CharSequence, templates: Seq[String], literal: Boolean, stepLimit: Int = 0): (Int, String)</code></pre>
<p>For example, the following code drops leading uppercase letters from letter-sequences, and turns <code>{</code> into <code>&lt;&lt;</code>, and <code>}</code> into <code>&gt;&gt;</code>.</p>
<pre><code>val re = Regex.fromSources(List(&quot;([A-Z]+)([a-z]+)&quot;, &quot;[{]&quot;, &quot;[}]&quot;, ... )
    re.rewriteAll(input, List(&quot;$2&quot;, &quot;&lt;&lt;&quot;, &quot;&gt;&gt;&quot;), ...
</code></pre>
<h3 id="lexical-scanning">Lexical Scanning</h3>
<p>The following method yields a sort of lexical scanner: namely an iterator that applies one of the <code>mappers</code> to each of the instances of <code>re</code> in the input. The mapper used in each case is that corresponding to (the index of) the matching instance. There must be at least as many mappers as there are branches of <code>re</code>. The groups of each instance are numbered from 1.</p>
<pre><code>  re.allSymbols[SYM](input: CharSequence, mappers: Seq[StringMatch=&gt;SYM], ...): Iterator[SYM] </code></pre>
<p>For example, the following code yields an iterator that classifies successive subsequences of <code>input</code> into <code>Param</code>s, <code>Identifier</code>s or <code>Noise</code>. A <code>Param</code> takes the form <code>${digits}</code> or <code>$digit</code>.</p>
<pre><code>val digits:  StringMatch =&gt; Symbol = { case  StringMatch(_, ds) =&gt; Param(ds.toInt) }
val letters: StringMatch =&gt; Symbol = { case  StringMatch(_, ls) =&gt; Identifier(ls) }
val noise:   StringMatch =&gt; Symbol = { case  StringMatch(_)  =&gt; Noise }

val re = Regex.fromSources(List(&quot;[$]{([0-9]+)}&quot;, &quot;[$]([0-9])&quot;, &quot;([A-Za-z][A-Za-z0-9])&quot;, &quot;.+&quot;), ... )
    re.allSymbols(input, List(digits, digits, letters, noise), ...)
</code></pre>
<h2 id="implementation-method">Implementation method</h2>
<p>Regular expressions are translated into programs for an abstract “recognition machine”. During matching, the machine simulates a nondeterministic finite state machine (NFA) by running a pool of <em>deterministic machines</em> (we call them <em>threads</em>) in pseudo-parallel: one for each unrefuted potential match. The state of each thread is embodied in its <em>program counter</em>, together with the starting and ending locations of each (parenthesised) group (it has so far) recognised.</p>
<p>Subject sequences are offered element by element to each thread in the pool, which either accepts, refutes, or jumps to its “next” instruction. Where there would be more than one outgoing edge from the state of the NFA, this “move” results in the construction of one (or more) additional <em>threads</em>. For example</p>
<pre><code>        r1 | r2 | r3</code></pre>
<p>translates to (the equivalent) of</p>
<pre><code>          goto L1, L2, L3
      L1: code to recognise r1
          goto END
      L2: code to recognise r2
          goto END
      L3: code to recognise r3
     END:          </code></pre>
<p>A deterministic match is refuted by an input that fails to match any outgoing edge from its current state; the corresponding machine drops out of the pool of active threads.</p>
<h3 id="potential-nontermination">Potential Nontermination</h3>
<p>The translation from regular expression to recognition machine code is straightforward, and no attempt is made to tarnsform the expression into a more efficient form, <em>or to a form that cannot (under some circumstances) cause non-termination</em>. With this in mind, the matching and searching methods may be given an upper bound to the number of recognition machine cycles they execute that causes them to abort if it is exceeded. <em>This is a pragmatic and expedient solution to the performance issues that would arise from an attempt to detect non termination: we find a more efficient method of non-termination detection in due course; but it’s not a priority for us.</em></p>
<h3 id="potential-speedups">Potential Speedups</h3>
<p>Whilst the cost of a failing anchored RE match (<code>matches</code> or <code>suffixes</code>) is bounded linearly by the product of its “length” and the length of the subject subsequence, this is not so for the unanchored matches (<code>findPrefix</code>, <code>findSuffix</code>), for these are implemented as anchored matches from adjacent positions in the subject: the aggregate cost being, therefore, quadratic in the length of the subject subsequence. The resulting performance is (better than) acceptable in a text editor, but could nevertheless be improved by using a two-stage search.</p>
<p>In the context of using the kit in a text editor we made some compromises with efficiency, and noted in the source code, <em>and we quote</em>:</p>
<ol type="1">
<li><p>I gratefully acknowledge my colleague Mike Spivey’s observation (based on the 1965 Thompson paper) that an appropriate technique for <em>searching</em> rather than <em>matching</em> is to spawn another thread at the origin of the program whenever the machine is about to move to consideration of the next element of a sequence.</p></li>
<li><p>Although implemented here (<em>i.e.</em> in the machine), the technique cannot be guaranteed to capture the content of nested groups appropriately during a search; indeed it can only ever be relied upon to find the end position of a match. One case in point is an expression of the form <code>(R1)+R2</code> when <code>R2</code> is empty, or has a prefix that may match a prefix of <code>R1</code>.</p></li>
<li><p>My judgment is that under many circumstances it is not worth trying to compose the above technique to find the endpoint of a match with a quadratic “match backwards” (from the endpoint) to capture groups accurately.</p></li>
</ol>
<p><em>end quote</em></p>
<p>We now believe that we should provide methods in the API that are implemented using the method sketched in (3). We’d welcome collaboration in implementing this. Much of the necessary machinery is already present in the current codebase.</p>
</body>
</html>
